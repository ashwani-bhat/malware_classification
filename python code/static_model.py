

l = ['Characteristics', 'MajorLinkerVersion', 'MinorLinkerVersion', 'SizeOfCode', 'SizeOfInitializedData', 'SizeOfUninitializedData', 'AddressOfEntryPoint', 'BaseOfCode', 'ImageBase', 'SectionAlignment', 'FileAlignment', 'MajorOperatingSystemVersion', 'MinorOperatingSystemVersion', 'MajorImageVersion', 'MinorImageVersion', 'MajorSubsystemVersion', 'MinorSubsystemVersion', 'SizeOfHeaders', 'CheckSum', 'Subsystem', 'DllCharacteristics', 'SizeOfStackReserve', 'SizeOfStackCommit', 'SizeOfHeapReserve', 'LoaderFlags']
# print((l))
# 'CM_Get_Device_IDW' in l


# In[2]:


# l = ['Characteristics','CheckSum','SizeOfImage','ImageBase','SizeOfInitializedData','BaseOfData','SizeOfCode','AddressOfEntryPoint','SizeOfUninitializedData','BaseOfCode']


# In[3]:


# l = ['Characteristics','CheckSum','SizeOfImage','SizeOfInitializedData','BaseOfData','SizeOfCode','AddressOfEntryPoint']


# In[4]:


import os
import json
import re
import pandas as pd


###################### RUN FROM HERE
df = pd.read_csv('staticData')
df.head()


# In[28]:


df = df.dropna(axis=1, how='all')
df = df.fillna(0)
df.head()
df['Subsystem'].value_counts()


# In[29]:


# df.drop_duplicates(inplace = True)


# In[30]:


for k in df.columns:
    if df[k].dtype != 'int64':
        df[k] = df[k].map(lambda name: int(name))


# In[31]:


df.info()


# In[32]:


X = df.drop(['malware Family'],axis = 1)
y = df['malware Family']
from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=2)
X.head(4)
y.head(4)
df.columns


# In[33]:


from sklearn.feature_selection import SelectKBest, chi2

#apply SelectKBest class to extract top 10 best features
bestfeatures = SelectKBest(score_func=chi2, k=6)
fit = bestfeatures.fit(X,y)
dfscores = pd.DataFrame(fit.scores_)
dfcolumns = pd.DataFrame(X.columns)
#concat two dataframes for better visualization 
featureScores = pd.concat([dfcolumns,dfscores],axis=1)
featureScores.columns = ['Specs','Score']  #naming the dataframe columns
print(featureScores.nlargest(5,'Score'))  #print 10 best features


# In[34]:



# In[35]:



# In[36]:


# from sklearn import preprocessing
# mm_scaler = preprocessing.MinMaxScaler()
# X_train = mm_scaler.fit_transform(X_train)
# X_test = mm_scaler.transform(X_test)
# X_train


# In[37]:


from sklearn.metrics import classification_report,confusion_matrix
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.ensemble import GradientBoostingClassifier
# clf = DecisionTreeClassifier()
clf = RandomForestClassifier(n_estimators=200,random_state=4)
# clf = GradientBoostingClassifier()
clf.fit(X_train,y_train)

y_pred = clf.predict(X_test)
cm = confusion_matrix(y_test, y_pred)
print(cm,'\n')
print((cm[0][0]+cm[1][1])/(cm[0][0]+cm[0][1]+cm[1][0]+cm[1][1]),'\n')
print(classification_report(y_test, y_pred))


# In[38]:


import pickle

filename = 'model.sav'
pickle.dump(clf, open(filename, 'wb'))
 

